---
title: (웨이커) 초당 3000건 이상의 트래픽 처리
category: WAIKER EXPERIENCE
order: 1
---

## 개장 (Market Open) 시점
<img src="https://github.com/chagchagchag/intro/blob/main/_docs/img/4.WAIKER-EXPERIENCE/MARKET-OPEN-AROUND.png?raw=true"/>

장 시작 전 (PRE MARKET) 에는 1초당 1k \~ 2.5k 정도였고 한국시간 기준 22:30 분 이후로 7500건(7.5k) 까지 트래픽이 치솟음을 확인 가능.
<br>


## 폐장 (Market Close) 시점
<img src="https://github.com/chagchagchag/intro/blob/main/_docs/img/4.WAIKER-EXPERIENCE/MARKET-CLOSE-AROUND.png?raw=true"/>

장 마감 시점 전후 에는 1초 당 평균 7500건 (7.5K) 의 트래픽이 치솟음을 확인 가능.


## MVCC 이슈
1초에 최소 2000건 \~ 최대 7000건의 데이터의 insert/update 를 일반적인 관계형 데이터베이스에서 수행한다면 MVCC 상의 단점에 무엇이 단점이 있는지 파악이 필요합니다.<br>

Postgresql 의 경우 MVCC 시에 기존의 Tree 를 Dead Tree로 만들고 새로운 Tree 로 만드는 방식을 채택하고 있기에 Dead Tree 가 계속해서 생겨납니다. 이런 작업이 고반복으로 계속해서 발생한다면 디스크 공간이 부족해 Disk Full 현상이 발생할 수 있는 현상으로 인해 Vaccum을 수행해줘야 하는 이슈가 발생합니다.<br>

당시 Vaccum 에 대해 해결할 수 있는 권한(계정권한)이 있는 인원들은 인프라팀 인원들이었는데, 당시 회사의 사정이 좋지 않아서 대부분 Off 상태인 경우가 많았습니다. 이런 이유로 Vaccum 을 제때에 수행하지 않아 Disk Full 로 인한 데이터 저장 지연 현상이 발생했었습니다.<br>
<br>

## 웹소켓 전송
DB에 데이터를 저장하는 것은 Insert/Update 할 행의 수를 조절해서 Batch 기반의 작업 처리를 하는 것으로 효율적인 처리가 가능하며, 데이터의 조회는 캐시에 업데이트 해두어 API 레벨에서는 캐시의 데이터를 응답하는 방식으로 효율적인 처리가 가능합니다.<br>

하지만, 웹소켓의 경우 세션을 소유한 모든 사용자에게 시세 데이터를 전송해야 했습니다. 그런데 당시 WEB/IOS/AOS 단말 모두에 웹소켓 시세를 전송하는 구조였기에, 스케쥴링 기반의 배치 전송을 한다고 하더라도 사용자가 많아지면 많아질수록 웹소켓 시세데이터를 전송해야 하는 세션들과 전송해야 하는 종목들로 인한 시간 복잡도의 깊이가 계속해서 올라갔습니다. <br>

이런 이유로 언젠가는 웹소켓 인스턴스는 가급적 K8S 기반의 분산환경 또는 Nginx 기반의 다중 인스턴스 소비자로 구성하는 작업을 시작해야 했습니다. <br>

이 당시 개발 기한도 부족하기도 했지만, 개발팀 내의 랩장님, 인프라 팀의 랩장님께 설명을 드려보아도 이 부분에 대해 이해를 도저히 못하셔서 설득을 포기하고 싱글 인스턴스 기반의 웹소켓 인스턴스의 스레드를 최적화 하는 것으로 개발을 마무리 지었었습니다.<br>

이 당시 웹소켓 데이터 전송시 사용한 캐시는 Hazelcast 라는 클러스터링이 가능한 오프힙 캐시를 사용했는데, 이 자료구조를 기반으로 세션과 자료구조들을 공유한다면 시세 데이터의 순서를 유지하면서 클러스터링 기반으로 웹소켓 기능의 클러스터링 구조 전환이 충분히 가능했습니다.<br>

만약, 다시 리팩토링을 하거나 고도화업무를 맡는다면 아마도 이 Websocket 인스턴스에 대해 컨테이너 기반의 클러스터링 구조로 전환을 했을 것 같습니다.<br>
<br>

